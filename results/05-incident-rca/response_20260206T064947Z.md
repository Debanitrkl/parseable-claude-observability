

# Root Cause Analysis â€” INC-2025-0115-001

## Checkout Success Rate Degradation

---

## 1. Root Cause Identification

| Attribute | Detail |
|---|---|
| **Root Cause** | Accidental misconfiguration of `payment-service` CPU resource limit during deployment v2.14.3 â€” reduced from `2000m` to `200m` (a 10x reduction due to a missing zero/typo in the deployment manifest). |
| **Confidence Level** | **99% â€” Virtually Certain** |

### Evidence Supporting This Conclusion

| Evidence Type | Detail | Weight |
|---|---|---|
| **Deployment diff** | `resources.limits.cpu` changed from `2000m` â†’ `200m` â€” confirmed unintended | Definitive |
| **CPU utilization** | 199m / 200m limit = 99.5% saturation | Definitive |
| **CFS throttle data** | 4,601 throttled periods / 187.3 seconds of throttled time in 5 minutes | Definitive |
| **Latency correlation** | p50 latency exploded from 187ms â†’ 3,891ms (20.8x increase), perfectly correlated with CPU starvation | Strong |
| **Monotonically rising throttle count** | `cpu_throttle_count` escalated from 847 â†’ 4,601 within 35 seconds of log window, indicating continuous and worsening CPU starvation | Strong |
| **Memory is healthy** | 50% memory utilization rules out memory pressure, GC storms, or OOM as contributing factors | Eliminates alternative |
| **No other changes** | No other deployments, no upstream payment-gateway errors (timeouts originate locally) | Eliminates alternative |

### Why This Manifested 6 Hours After Deployment

The CPU limit of 200m was sufficient to handle low-traffic periods (early morning UTC). As traffic ramped to normal daytime checkout volumes around 14:25 UTC, the payment-service hit its artificially constrained CPU ceiling. The Linux CFS (Completely Fair Scheduler) began aggressively throttling the container, causing request processing latency to balloon beyond the 2,000ms gRPC deadline.

---

## 2. Complete Failure Chain

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FAILURE CHAIN (Step by Step)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

 TRIGGER (08:25 UTC â€” T-6h)
 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 â”‚  Deployment v2.14.3 applied to payment-service.
 â”‚  Intended change: TLS certificate rotation.
 â”‚  Unintended change: CPU limit 2000m â†’ 200m (typo).
 â”‚  Impact: None yet â€” low morning traffic fits within 200m.
 â”‚
 â–¼
 STEP 1 â€” CPU Saturation (14:25 UTC â€” T+0)
 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 â”‚  Daytime traffic reaches normal checkout volume.
 â”‚  payment-service CPU demand exceeds 200m limit.
 â”‚  Linux CFS throttles container: 847 throttle events in first seconds.
 â”‚  CPU usage pinned at 199m/200m (99.5%).
 â”‚
 â–¼
 STEP 2 â€” Latency Explosion
 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 â”‚  CFS throttling pauses process execution mid-request.
 â”‚  Request processing time inflates from ~187ms (p50) to ~3,891ms (p50).
 â”‚  Every outbound gRPC call to payment-gateway exceeds the 2,000ms deadline.
 â”‚  All calls return DeadlineExceeded errors.
 â”‚
 â–¼
 STEP 3 â€” Cascading Failures to checkout-service
 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 â”‚  checkout-service receives DeadlineExceeded from payment-service.
 â”‚  Retry logic activates: up to 3 retries per order.
 â”‚  Each retry also hits a throttled payment-service â†’ also times out.
 â”‚
 â–¼
 STEP 4 â€” Retry Amplification (Worsening Feedback Loop)
 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 â”‚  3x retry multiplier increases load on already-saturated payment-service.
 â”‚  More requests â†’ more CPU demand â†’ more throttling â†’ worse latency.
 â”‚  Throttle count accelerates: 847 â†’ 1203 â†’ 1589 â†’ 1923 â†’ ... â†’ 4601.
 â”‚  A single order with retries holds resources for up to 15,234ms (Trace abc003).
 â”‚
 â–¼
 STEP 5 â€” Customer Impact
 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 â”‚  38.7% of payment requests fail with DeadlineExceeded.
 â”‚  checkout-service success rate drops from 99.2% â†’ 61.3%.
 â”‚  Users see: "Payment processing failed, please try again"
 â”‚  Frontend returns HTTP 502 (single attempt) or 504 (retry exhaustion).
 â”‚
 â–¼
 STEP 6 â€” Alert Fires (14:28 UTC â€” T+3min)
 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 â”‚  SLO burn rate alert triggers in PagerDuty.
 â”‚  3-minute detection gap (Time-to-Detect).
 â”‚
 â–¼
 STEP 7 â€” Resolution (14:52 UTC â€” T+27min)
 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Incident resolved (likely by restoring CPU limit to 2000m
    or rolling back the deployment).
```

### Architectural Diagram of Failure Propagation

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Frontend â”‚â”€â”€â”€â”€â”€â–¶â”‚ checkout-service  â”‚â”€â”€â”€â”€â”€â–¶â”‚ payment-service â”‚
    â”‚          â”‚ 502  â”‚                  â”‚ gRPC â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚          â”‚ 504  â”‚  Retry logic     â”‚ Err  â”‚  â”‚ CPU: 99.5% â”‚  â”‚
    â”‚          â”‚â—€â”€â”€â”€â”€â”€â”‚  (1/3, 2/3, 3/3) â”‚â—€â”€â”€â”€â”€â”€â”‚  â”‚ CFS Throt. â”‚  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  â”‚ 4601 evts  â”‚  â”‚
         â”‚                    â”‚                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â–¼                    â–¼                  â”‚        â”‚         â”‚
    Users see           Success rate             â”‚        â–¼         â”‚
    "Payment            99.2% â†’ 61.3%           â”‚  Latency: 3.9s  â”‚
     failed"                                    â”‚  (was 187ms)    â”‚
                                                 â”‚        â”‚         â”‚
                                                 â”‚        â–¼         â”‚
                                                 â”‚  gRPC deadline  â”‚
                                                 â”‚  2000ms EXCEEDED â”‚
                                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â–²
                                                         â”‚
                                                  ROOT CAUSE:
                                              CPU limit 2000mâ†’200m
                                                 (deploy typo)
```

---

## 3. Immediate Remediation Steps

### Actions to Resolve (in priority order)

| Priority | Action | Expected Impact | ETA |
|---|---|---|---|
| **P0** | **Restore CPU limit** to `2000m` via `kubectl patch` or manifest fix + apply | Immediately eliminates CFS throttling; latency returns to ~187ms p50 | 2â€“3 min |
| **P0** | Verify recovery: confirm CFS throttle count stops increasing, p50 latency drops below 300ms, error rate returns to <1% | Confirms fix is effective | 5 min |
| **P1** | Monitor for payment-gateway side effects â€” check for duplicate charges from retried requests that may have partially succeeded upstream | Prevent revenue/trust impact | 15 min |
| **P1** | Audit orders that failed during the 27-minute window â€” generate list of `ord_*` IDs for customer support follow-up | Customer recovery | 30 min |
| **P2** | Communicate resolution to stakeholders via incident channel | Transparency | 10 min |

### Remediation Command (example)

```bash
# Emergency fix â€” patch CPU limit back to correct value
kubectl patch deployment payment-service -n production \
  --type='json' \
  -p='[{"op": "replace", "path": "/spec/template/spec/containers/0/resources/limits/cpu", "value": "2000m"}]'

# Verify rollout
kubectl rollout status deployment/payment-service -n production --timeout=120s

# Confirm throttling has stopped
kubectl top pods -l app=payment-service -n production
```

---

## 4. Long-Term Prevention Measures

### A. Process & Deployment Safeguards

| # | Measure | Description | Priority |
|---|---|---|---|
| 1 | **Resource change validation in CI/CD** | Add a pipeline check that flags any change to `resources.limits` or `resources.requests` fields, requiring explicit approval from SRE. Treat resource specs as infrastructure-critical like replica counts. | **Critical** |
| 2 | **Diff review enforcement** | Require that deployment diffs are reviewed with full context (not just application code). Tools like `kubediff`, `pluto`, or ArgoCD diff views should highlight resource changes prominently. | **Critical** |
| 3 | **OPA/Kyverno admission policy** | Deploy a Kubernetes admission controller policy that rejects pod specs where `resources.limits.cpu` drops by more than 50% compared to the running deployment, unless annotated with an override. | **High** |
| 4 | **Canary/progressive rollout** | Use progressive delivery (Argo Rollouts, Flagger) with automated latency and error-rate analysis. A 10x latency increase would have triggered automatic rollback during canary phase. | **High** |
| 5 | **Separate infra changes from app changes** | TLS cert rotation should not be bundled in the same manifest change as resource specs. Use sealed-secrets, cert-manager, or external secret stores so certs are rotated independently of deployment manifests. | **Medium** |

### B. Observability & Alerting

| # | Measure | Description | Priority |
|---|---|---|---|
| 6 | **CFS throttle alert** | Create an alert on `container_cpu_cfs_throttled_periods_total` rate â€” fire when throttle ratio exceeds 25% sustained for 2 minutes. This would have detected the issue at ~08:30 UTC (6 hours earlier) during the first traffic bump. | **Critical** |
| 7 | **CPU limit utilization alert** | Alert when `container_cpu_usage_seconds_total / container_spec_cpu_quota` exceeds 85% for >1 minute. | **Critical** |
| 8 | **Post-deploy latency comparison** | Automated comparison of p50/p99 latency in the 30 minutes post-deploy vs. the prior baseline. A 20x increase would be immediately flagged. | **High** |
| 9 | **Resource configuration drift detection** | Periodic reconciliation check that compares running resource specs against a source-of-truth (e.g., Terraform state, GitOps repo) to detect unintended drift. | **Medium** |

### C. Resilience Improvements

| # | Measure | Description | Priority |
|---|---|---|---|
| 10 | **Retry budget / circuit breaker** | checkout-service should implement a circuit breaker pattern. After N consecutive DeadlineExceeded errors, stop retrying and fail fast. The current 3x retry on a saturated service created amplification (trace abc003 took 15.2 seconds). | **High** |
| 11 | **Retry with backoff + jitter** | If retries are kept, add exponential backoff with jitter to prevent thundering herd on recovery. | **High** |
| 12 | **Deadline propagation** | Ensure the frontend's overall timeout (appears to be ~15s for 504) is propagated as a gRPC deadline to downstream services, so retries don't extend beyond what the user will wait for. | **Medium** |
| 13 | **HPA based on CPU utilization** | Configure HorizontalPodAutoscaler targeting 70% CPU utilization. Even with the incorrect 200m limit, HPA would have scaled from 3 to ~30 replicas, partially mitigating the impact (though not ideal). | **Medium** |
| 14 | **Idempotency for payment operations** | Ensure payment-gateway calls are idempotent (idempotency keys) so retried requests don't risk duplicate charges. | **High** |

---

## 5. Incident Timeline Summary

```
08:25 UTC  â”Š  payment-service v2.14.3 deployed (CPU limit typo: 2000m â†’ 200m)
            â”Š  No immediate impact â€” low traffic period
            â”Š
            â”Š  ~~~~~~~ 6 hours of latent misconfiguration ~~~~~~~
            â”Š
14:25 UTC  â”Š  Traffic reaches threshold; CPU saturates at 200m limit
            â”Š  CFS throttling begins; latency spikes 20x
            â”Š  gRPC deadlines exceeded on all payment calls
            â”Š  Checkout success rate: 99.2% â†’ 61.3%
            â”Š
14:28 UTC  â”Š  PagerDuty alert fires (SLO burn rate)     TTD: 3 min
            â”Š
14:52 UTC  â”Š  Incident resolved (CPU limit restored)    TTR: 27 min
            â”Š
            â”Š  Total customer impact window: 27 minutes
            â”Š  Estimated failed checkouts: ~38.7% of traffic Ã— 27 min
```

---

## 6. Classification

| Dimension | Value |
|---|---|
| **Category** | Configuration error |
| **Trigger** | Human error (typo in deployment manifest) |
| **Contributing factors** | No resource-change validation in CI/CD; no CFS throttle alerting; retry amplification; 6-hour latent period due to traffic patterns |
| **Blast radius** | All checkout transactions for 27 minutes (~38.7% failure rate) |
| **Data loss / financial risk** | Possible duplicate charges from retried payments â€” requires audit |
| **MTTR** | 27 minutes (3 min detection + 24 min diagnosis & remediation) |

---

## 7. Action Items

| ID | Action | Owner | Due | Status |
|---|---|---|---|---|
| AI-001 | Add CI/CD guardrail for resource limit changes | Platform Eng | 1 week | ğŸ”´ Open |
| AI-002 | Deploy CFS throttle + CPU saturation alerts | SRE | 3 days | ğŸ”´ Open |
| AI-003 | Implement circuit breaker in checkout-service | Payments Team | 2 weeks | ğŸ”´ Open |
| AI-004 | Add OPA policy for resource change validation | Platform Eng | 2 weeks | ğŸ”´ Open |
| AI-005 | Audit all orders during incident window for duplicate charges | Payments Team | 1 day | ğŸ”´ Urgent |
| AI-006 | Post-deploy automated latency regression check | SRE | 2 weeks | ğŸ”´ Open |
| AI-007 | Separate TLS cert management from deployment manifests | Payments Team | 1 month | ğŸ”´ Open |