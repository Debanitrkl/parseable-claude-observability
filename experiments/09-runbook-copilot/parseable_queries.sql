-- Experiment 09: Runbook + On-Call Copilot - Parseable SQL Queries
-- These are the Parseable queries from the diagnostic runbook generated by Claude.
-- All queries use PostgreSQL-compatible SQL, executed by Parseable's DataFusion query engine.
-- Stream: astronomy-shop-logs (OpenTelemetry demo app)

-- =============================================================================
-- TURN 1: INITIAL DIAGNOSTIC RUNBOOK
-- =============================================================================

-- 1. Recent errors from the checkout service log stream
--    First step: understand the error volume and pattern
SELECT
    p_timestamp,
    severity_text,
    endpoint,
    error_message,
    span_trace_id,
    "http.status_code"
FROM
    "astronomy-shop-logs"
WHERE
    severity_text = 'ERROR'
    AND "service.name" = 'checkout-service'
    AND p_timestamp > NOW() - INTERVAL '30 minutes'
ORDER BY
    p_timestamp DESC
LIMIT 100;

-- 2. Error rate over time - identify when the problem started
SELECT
    DATE_TRUNC('minute', p_timestamp) AS minute,
    COUNT(*) AS total_requests,
    COUNT(*) FILTER (WHERE severity_text = 'ERROR') AS error_count,
    ROUND(
        CAST(COUNT(*) FILTER (WHERE severity_text = 'ERROR') AS FLOAT)
        / CAST(COUNT(*) AS FLOAT) * 100, 2
    ) AS error_rate_pct
FROM
    "astronomy-shop-logs"
WHERE
    "service.name" = 'checkout-service'
    AND p_timestamp > NOW() - INTERVAL '1 hour'
GROUP BY
    DATE_TRUNC('minute', p_timestamp)
ORDER BY
    minute DESC;

-- 3. Breakdown by endpoint - which routes are affected
SELECT
    endpoint,
    COUNT(*) AS error_count,
    COUNT(DISTINCT span_trace_id) AS affected_traces
FROM
    "astronomy-shop-logs"
WHERE
    severity_text = 'ERROR'
    AND "service.name" = 'checkout-service'
    AND p_timestamp > NOW() - INTERVAL '30 minutes'
GROUP BY
    endpoint
ORDER BY
    error_count DESC;

-- 4. Check for slow queries or long-running operations
--    Transactions that take abnormally long may be holding connections
SELECT
    p_timestamp,
    endpoint,
    duration_ms,
    db_query_duration_ms,
    span_trace_id,
    body
FROM
    "astronomy-shop-logs"
WHERE
    "service.name" = 'checkout-service'
    AND duration_ms > 5000
    AND p_timestamp > NOW() - INTERVAL '1 hour'
ORDER BY
    duration_ms DESC
LIMIT 50;

-- 5. Correlate with upstream service errors
--    Check if the payment service is experiencing issues
SELECT
    p_timestamp,
    severity_text,
    operation,
    error_message,
    duration_ms,
    span_trace_id
FROM
    "astronomy-shop-logs"
WHERE
    "service.name" = 'payment-service'
    AND severity_text IN ('ERROR', 'WARN')
    AND p_timestamp > NOW() - INTERVAL '1 hour'
ORDER BY
    p_timestamp DESC
LIMIT 50;

-- 6. Cross-service trace correlation
--    Find traces that span both checkout and payment services
--    to see the full request flow during the incident
SELECT
    p_timestamp,
    "service.name",
    severity_text,
    endpoint,
    "http.status_code",
    duration_ms,
    error_message,
    span_span_id
FROM
    "astronomy-shop-logs"
WHERE
    span_trace_id IN (
        SELECT DISTINCT span_trace_id
        FROM "astronomy-shop-logs"
        WHERE severity_text = 'ERROR'
            AND "service.name" = 'payment-service'
            AND error_message LIKE '%context deadline exceeded%'
            AND p_timestamp > NOW() - INTERVAL '1 hour'
    )
    AND "service.name" = 'checkout-service'
    AND p_timestamp > NOW() - INTERVAL '1 hour'
ORDER BY
    p_timestamp ASC;

-- =============================================================================
-- TURN 2: DEEPER INVESTIGATION (after initial results)
-- =============================================================================

-- 7. Identify the exact pattern of "context deadline exceeded" from payment service
--    Determine if this is a sustained pattern or burst
SELECT
    DATE_TRUNC('minute', p_timestamp) AS minute,
    COUNT(*) AS timeout_count,
    COUNT(DISTINCT span_trace_id) AS unique_traces
FROM
    "astronomy-shop-logs"
WHERE
    "service.name" = 'payment-service'
    AND error_message LIKE '%context deadline exceeded%'
    AND p_timestamp > NOW() - INTERVAL '2 hours'
GROUP BY
    DATE_TRUNC('minute', p_timestamp)
ORDER BY
    minute ASC;

-- 8. Find checkout requests that started a DB transaction but never completed
--    Look for "BEGIN" without a corresponding "COMMIT" or "ROLLBACK" in logs
SELECT
    p_timestamp,
    span_trace_id,
    correlation_id,
    body,
    endpoint,
    duration_ms
FROM
    "astronomy-shop-logs"
WHERE
    "service.name" = 'checkout-service'
    AND (body LIKE '%begin transaction%' OR body LIKE '%BEGIN%')
    AND span_trace_id NOT IN (
        SELECT span_trace_id
        FROM "astronomy-shop-logs"
        WHERE "service.name" = 'checkout-service'
            AND (body LIKE '%commit%' OR body LIKE '%COMMIT%'
               OR body LIKE '%rollback%' OR body LIKE '%ROLLBACK%')
            AND p_timestamp > NOW() - INTERVAL '2 hours'
    )
    AND p_timestamp > NOW() - INTERVAL '2 hours'
ORDER BY
    p_timestamp DESC;

-- =============================================================================
-- TURN 3: ROOT CAUSE ANALYSIS (post-remediation)
-- =============================================================================

-- 9. Compare error patterns before and after the v2.14.3 deploy
--    Deploy was at 2025-01-24T14:00:00Z
SELECT
    CASE
        WHEN p_timestamp < '2025-01-24T14:00:00Z' THEN 'before_deploy'
        ELSE 'after_deploy'
    END AS period,
    COUNT(*) AS total_requests,
    COUNT(*) FILTER (WHERE severity_text = 'ERROR') AS error_count,
    COUNT(*) FILTER (WHERE error_message LIKE '%connection pool%') AS pool_errors,
    ROUND(APPROX_PERCENTILE_CONT(duration_ms, 0.99), 2) AS p99_latency_ms
FROM
    "astronomy-shop-logs"
WHERE
    "service.name" = 'checkout-service'
    AND p_timestamp > '2025-01-24T00:00:00Z'
    AND p_timestamp < '2025-01-25T06:00:00Z'
GROUP BY
    CASE
        WHEN p_timestamp < '2025-01-24T14:00:00Z' THEN 'before_deploy'
        ELSE 'after_deploy'
    END
ORDER BY
    period;

-- 10. Find the first occurrence of idle-in-transaction related issues after deploy
--     Look for slow requests that correlate with payment timeouts
SELECT
    p_timestamp,
    endpoint,
    duration_ms,
    error_message,
    span_trace_id,
    correlation_id
FROM
    "astronomy-shop-logs"
WHERE
    "service.name" = 'checkout-service'
    AND (duration_ms > 5000 OR error_message LIKE '%timeout%' OR error_message LIKE '%deadline%')
    AND p_timestamp > '2025-01-24T14:00:00Z'
ORDER BY
    p_timestamp ASC
LIMIT 20;

-- 11. Identify which specific endpoint/code path leaks transactions
--     Group long-running requests by endpoint after the deploy
SELECT
    endpoint,
    COUNT(*) AS slow_request_count,
    ROUND(AVG(duration_ms), 2) AS avg_duration_ms,
    ROUND(APPROX_PERCENTILE_CONT(duration_ms, 0.99), 2) AS p99_duration_ms,
    COUNT(DISTINCT span_trace_id) AS unique_traces
FROM
    "astronomy-shop-logs"
WHERE
    "service.name" = 'checkout-service'
    AND duration_ms > 5000
    AND p_timestamp > '2025-01-24T14:00:00Z'
GROUP BY
    endpoint
ORDER BY
    slow_request_count DESC;

-- 12. Get log stream stats via Parseable API
--     Useful for understanding ingestion volume and storage during the incident
--
-- curl -s "http://parseable:8000/api/v1/logstream/astronomy-shop-logs/stats" \
--   -H "Authorization: Basic <base64-credentials>" | jq .

-- 13. Hourly connection pool error trend since deploy
--     Helps determine if this was a gradual leak or sudden failure
SELECT
    DATE_TRUNC('hour', p_timestamp) AS hour,
    COUNT(*) FILTER (WHERE error_message LIKE '%connection pool%') AS pool_errors,
    COUNT(*) FILTER (WHERE error_message LIKE '%idle in transaction%') AS idle_txn_mentions,
    COUNT(*) AS total_events
FROM
    "astronomy-shop-logs"
WHERE
    "service.name" = 'checkout-service'
    AND p_timestamp > '2025-01-24T14:00:00Z'
GROUP BY
    DATE_TRUNC('hour', p_timestamp)
ORDER BY
    hour ASC;
